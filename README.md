# SystemsAnalysis-KKBOX_Challenge

## System Analysis Report
We, as a group analyzing, solving, and interpreting __KKBOX's__ main problem, primarily after reading the project _requirements_, noted the main aspects in which __users__, __songs__, their __context__, and __time__ could help us generate an efficient _system_ for predicting musical tastes for future listeners.

We took the main concepts of _systemic analysis_, compared them, and defined each aspect in our report, such as __listening events__, the __relationships__ between __users__ and __songs__, the _complexity_ and _sensitivity_ of the system, information available in the _data sets_, and _system boundaries_, etc... Based on all of the above, we linked terms and were able to determine our strategy for the Kaggle competition, focusing on our _strengths_ and trying to improve our _weaknesses_.

This is the main Overleaf document, which we used to make the report about the Kaggle competition. https://www.overleaf.com/project/67f5f01d92c80a0d831bfc5e (we´ve uploaded the main document in PDF as well :D.)

## System Design
Throughout the workshop, we analyzed and developed the architecture of the __KKBOX Music Recommendation System__, guided by the principles of __systemic analysis__. Using the provided datasets, we explored how __users__, __songs__, __listening events__, and __contextual variables__ such as time and source type interact within the system. Our focus was to design an architecture capable of managing _noise_, _missing data_, and _chaotic user behavior_ while maintaining high predictive performance.

The architectural diagrams _Global System and Data Ingestion_ illustrate the modular structure and the interaction between layers such as __Data Management__, __Feature Processing__, __Model Core__, and __Monitoring & Control__. Each layer plays a critical role in ensuring _stability_, _scalability_, and _adaptability_ under real-world streaming conditions.

## Robust System Design and Project Management

This stage of the project focuses on strengthening the KKBOX Music Recommendation System through __resilient design__ and __structured management__ practices. The proposed architecture follows a _modular_, _fault-tolerant_ layout that maintains _reliability_ even when facing _noisy data_ or unexpected failures. Using principles from _Six Sigma_ and _ISO 27001_, the system integrates __validation__, __logging__, and __recovery layers__ that safeguard _data integrity_, support _consistent performance_, and ensure _security_ across all processes. _Real-time monitoring_ and _feedback_ mechanisms are incorporated to detect instability early and trigger automated corrections.

In parallel, the management plan establishes clear __team roles__ and __iterative development practices__. Through coordinated _workflows supported_ by _Kanban tracking_, milestone scheduling, and periodic evaluations the team maintains progress visibility and continuous improvement. Combined with regular _retraining_ and __risk control strategies__, this framework promotes a _scalable_, _maintainable_, and _quality-driven_ system ready for long-term operation.

## Kaggle System Simulation

To simulate the behavior of the __KKBOX system__, the project first focused on preparing _realistic_ and _stable_ data inputs. All competition _files members_, _songs_, extra _metadata_, and interaction logs were _merged_ and _cleaned_ to eliminate __unusable values__, __unify formats__, and __prevent misleading patterns__ during _modeling_. This resulted in a consolidated dataset of more than _seven million records_, with _missing attributes imputed_ and _invalid_ ages filtered out. A __smaller 50k-row slice__ was also extracted to keep certain _validation runs_ manageable. With this refined _dataset_, a supervised learning _pipeline_ was planned using a __Random Forest model__, following consistent encoding strategies and a reproducible _80/20 train–test split_. The model trained on eight _filtered features_ delivered interpretable _probabilities_ and performance logs, revealing that _learning stability_ depended heavily on clean _categorical spaces_ and reduced noise.

In parallel, a _second simulation_ explored __event-based behavior__ through a __Cellular Automata prototype__. A __50×50 grid__ was _iterated over time_, applying localized events such as _replay activation_, _neighborhood influence_, and _noise driven flips_. These rules were designed to _mimic_ how _listening behaviors_ might __spread__ or __fade__ within a _population_. Multiple runs showed that _small probability_ changes could produce dramatically __different global outcomes__, highlighting the system’s _sensitivity_ to _perturbations_. Together, both _simulations_ validated the _architecture_ by showing how _data flows_, __prediction routines__, and _emergent patterns_ behave under _controlled experiments_, reinforcing the earlier design decisions made in Workshops 1–3.